# Building and Running Luthier

## Requirements

### Supported AMD GPUs

At the time of writing Luthier has been developed and tested on an AMD Instinct MI 100, a CDNA 1 GPU. No other AMD GPUs
have been tested with Luthier (yet). Other CDNA GPUs might not work due to bugs; RDNA GPUs might also not work due to
bugs, and some hardware differences currently not taken into account. As development progresses, we will add support
for more GPUs.

### Operating System

Luthier should build and run on any Linux-based distribution with ROCm support. At the time of writing, AMD officially
distributes ROCm for Ubuntu, Red Hat Enterprise Linux, and SUSE Linux(see
[ROCm Installation Options](https://rocm.docs.amd.com/projects/install-on-linux/en/latest/tutorial/install-overview.html)
). Other distributions like Arch might also have support either in their official repositories or community-maintained
repositories.

Luthier currently does not support Windows; This might change in the future.

### Required Non-ROCm Software

1. **[CMake](https://cmake.org/)** is used as the build system for Luthier. **[Ninja](https://ninja-build.org/)** is 
   the preferred CMake generator for Luthier; But any other generator e.g. 
   **[GNU Make](https://www.gnu.org/software/make/)** should also work. The [CMakeLists.txt](../CMakeLists.txt) file for
   Luthier is located at the top-level directory of the project. **CMake v3.21 and above** is required, since it is 
   the earliest version that supports HIP as a language with built-in HIP/ROCm-specific CMake variables.
2. **A C/C++ compiler**, like [GNU GCC](https://gcc.gnu.org/) or [Clang](https://clang.llvm.org/) for compiling the host
   portion of Luthier.
3. A Python 3 interpreter, and the **[CXX Header Parser](https://github.com/robotpy/cxxheaderparser)** and
   **[PCPP](https://github.com/ned14/pcpp)** Python packages are used to generate wrappers for HSA and HIP API 
   functions by inspecting the ROCm headers Luthier is being built against.

### Required ROCm Software

1. **[AMDGPU DKMS](https://docs.amd.com/projects/install-on-linux/en/latest/how-to/native-install/ubuntu.html#register-kernel-mode-driver)** 
   is the kernel-mode driver for AMD GPUs. Without this, no ROCm-based application is able to run
   on the system.
2. **[AMD Code Object Manager Library (COMGR)](https://github.com/ROCm/llvm-project/tree/amd-staging/amd/comgr)** 
   is used for linking the object files generated by Luthier into HSA executables at runtime.
3. **[ROCm Runtime Library (ROCr)](https://github.com/ROCm/ROCR-Runtime)** is required to run AMDGPU compute
   kernels on Linux systems. Luthier uses ROCr to intercept calls to AMD's Heterogeneous Systems Architecture (HSA)
   implementation (including kernel launches), loading/unloading instrumentation code,
   querying the HSA agents (GPUs) present on the system, and other core GPU functionality needed by AMD GPUs for
   instrumentation.
4. **[AMD Compute Language Runtimes](https://github.com/ROCm/clr)** provides the runtime for AMD's
   Heterogeneous-Compute Interface for Portability (HIP). Luthier requires the HIP runtime to load user-written device
   functions for instrumentation, and write tool-side logic.
5. **[LLVM](https://llvm.org/)** is the main driving force of Luthier. Its AMD GPU backend is used to lift code objects 
   into their equivalent LLVM MIR representation for inspection, and also generating instrumented code objects, all
   during runtime. LLVM's standard libraries (e.g. `ADT`, string formatting, etc.) are also widely used across Luthier.
   Even though the ROCm stack is shipped with a stable version of LLVM (version 18, at the time of writing),
   Luthier opts to use the latest ROCm LLVM (version 20, at the time of writing) from the
   [amd-staging](https://github.com/ROCm/llvm-project/tree/amd-staging) branch; This is because:
    1. Luthier depends on features that have been recently introduced to LLVM. One primary example of such feature is
       support for the new pass manager in the CodeGen layer.
    2. ROCm LLVM does not ship with Runtime Type Information (RTTI) enabled. Luthier uses RTTI-backed features in LLVM
       for things like error checking, note section parsing, and string formating.
   
   In addition to a suitable installation of LLVM, Luthier requires **the source code of the LLVM project** being used 
   to build it. This is because:
    1. The AMDGPU tablegen records for the instructions and registers described by the AMDGPU target are only 
       available in the LLVM source code.
    2. The concrete interface header of target-agnostic CodeGen classes for the AMDGPU backend (e.g.
       `llvm::SIMachineFunctionInfo`) as well as some useful utilities (e.g. getting the width of a register as well as
       its target class) is only available inside the LLVM source code and required for correct functionality of Luthier.
       Note that Luthier only includes these header files and does not compile their implementation from scratch as
       they are already available inside AMD GPU specific LLVM libraries.
   
   Luthier does not require the LLVM source code for writing and running Luthier tools, as all required files from the
   LLVM source code will be installed under Luthier's include directory.
6. **[Clang Compiler](https://clang.llvm.org/)** is used to compile Luthier tools, primarily their device portion.
   It must be built against the same LLVM version used to build Luthier itself, otherwise the version mismatch
   might cause segfaults during builds.
7. **[ROCm Device Library](https://github.com/ROCm/llvm-project/tree/amd-staging/amd/device-libs)**
   is a library of AMD specific device-side language runtime libraries needed by the Clang compiler used to compile 
   Luthier.
8. **[ROCProfiler SDK](https://github.com/rocm/rocprofiler-sdk)** is used to capture the HIP and HSA API tables and 
   install callbacks. It can also be used to pair advanced profiling features with Luthier's instrumentation 
   capabilities.

**Luthier requires ROCm version 6.2.2+, and supports instrumenting Code Object V3+**. 

## Build Options

### Luthier-specific CMake Options
- **```LUTHIER_LLVM_SRC_DIR```**: If set, should point to the source code of the LLVM binary used to build
  Luthier. This is useful for when the LLVM source code is readily available on the system. Otherwise, Luthier 
  will inspect the `llvm/Support/VCSRevision.h` header file of the LLVM binary found by CMake and downloads 
  the associated source code revision automatically as an external resource. The downloaded source code can 
  be accessed under the CMake build folder.  
- **```LUTHIER_BUILD_EXAMPLES```**: Builds the example tools under the [examples](../examples) folder if set to
  ```ON```. It is enabled by default.
- **```LUTHIER_BUILD_UNIT_TESTS```**: Builds Luthier's unit test set to ```ON```. Disabled
  by default.
- **```LUTHIER_BUILD_INTEGRATION_TESTS```**: Builds Luthier's integration test if set to ```ON```. Disabled
  by default.
- **```LUTHIER_BUILD_LATEX_DOCS```**: Builds Luthier's documentation in PDF format with Doxygen using Latex if set to
  ```ON```; Disabled by default. TODO: Describe Latex dependencies and procedure.
- **```LUTHIER_BUILD_HTML_DOCS```**: Builds Luthier's documentation in HTML format with Doxygen if set to ```ON```;
  Disabled by default. TODO: Describe documentation build procedure.

### Useful CMake Options and Commands
Refer to [CMake docs](https://cmake.org/documentation/) for more information.

- **```CMAKE_PREFIX_PATH```** is a list of `;`-separated paths that CMake will recursively search to locate 
  requested packages via `find_package`. Earlier specified paths are prioritized.
- **```{PACKAGE_NAME}_DIR```**, with `PACKAGE_NAME` replaced with the name of the package (e.g. `hip`) can force
  CMake to locate the config file of the package under the given directory and ignore all other hints.
- **```CMAKE_CXX_COMPILER```**, **```CMAKE_C_COMPILER```**, and **```CMAKE_HIP_COMPILER``` set paths to the
  desired C/C++/HIP compiler.
- **```-G```** sets the build configuration generator for CMake (e.g., ninja).
- **```CMAKE_BUILD_TYPE```** can enable/disable build with source debug information if set to ```Debug``` or
  ```RelWithDebugInfo```. Keep in mind that enabling this option might enable the debug flag for both host and device
  code, which usually results in tons of metadata info being printed when inspecting contents of instrumentation module 
  LLVM IR.
- **```cmake --build . -v --```** prints each individual build step executed for a target. 
  Very useful for debugging the build process.

## Build Instructions

> [!NOTE]
> `/opt/luthier/` is the assumed installation prefix for Luthier and its requirements.
>  You don't have to follow this convention.

1. Ensure all requirements are met (besides LLVM and Clang); See [Build Requirements](#build-requirements) and 
   [ROCm Installation Instructions](https://rocm.docs.amd.com/en/latest/index.html).
2. Ensure that compiler and LLVM requirements of Luthier are met (if not already):
   1. Clone the `amd-staging` of the ROCm fork of the LLVM project:
      ```bash
      git clone --depth 1 https://github.com/ROCm/llvm-project/
      ```
   2. Configure, build, and install the required components from the LLVM project (Ninja is used to generate the 
      build files here):
      ```bash
      mkdir llvm-project/build && cd llvm-project/build &&  \
      cmake -G Ninja -DCMAKE_POSITION_INDEPENDENT_CODE=ON \
      -DCMAKE_INSTALL_PREFIX=/opt/luthier/llvm/  \
      -DCMAKE_BUILD_TYPE=Release \
      -DLLVM_TARGETS_TO_BUILD="AMDGPU;X86"  \
      -DLLVM_ENABLE_PROJECTS="llvm;clang;lld;compiler-rt;clang-tools-extra" \
      -DLLVM_ENABLE_RUNTIMES="libcxx;libcxxabi;libunwind" \
      -DLLVM_ENABLE_EXPENSIVE_CHECKS=OFF \
      -DLIBCXX_ENABLE_SHARED=OFF \
      -DLIBCXX_ENABLE_STATIC=ON \
      -DLIBCXX_INSTALL_LIBRARY=OFF \
      -DLIBCXX_INSTALL_HEADERS=OFF \
      -DLIBCXXABI_ENABLE_SHARED=OFF \
      -DLIBCXXABI_ENABLE_STATIC=ON \
      -DLIBCXXABI_INSTALL_STATIC_LIBRARY=OFF \
      -DLLVM_ENABLE_RTTI=ON \
      -DLLVM_OPTIMIZED_TABLEGEN=ON \
      -DCLANG_ENABLE_AMDCLANG=ON \
      -DLLVM_BUILD_TOOLS=ON \
      -DLLVM_BUILD_EXAMPLES=OFF \
      -DLLVM_INCLUDE_BENCHMARKS=OFF \
      -DLLVM_BUILD_TESTS=OFF \
      -DLLVM_INCLUDE_TESTS=OFF \
      -DCLANG_INCLUDE_TESTS=OFF \
      -DLLVM_BUILD_DOCS=OFF \
      -DLLVM_ENABLE_SPHINX=OFF \
      -DSPHINX_WARNINGS_AS_ERRORS=OFF \
      -DSPHINX_OUTPUT_MAN=OFF \
      -DLLVM_ENABLE_ASSERTIONS=OFF \
      -DLLVM_ENABLE_Z3_SOLVER=OFF \
      -DLLVM_ENABLE_ZLIB=ON \
      -DLLVM_AMDGPU_ALLOW_NPI_TARGETS=ON \
      -DCLANG_DEFAULT_PIE_ON_LINUX=0 \
      -DCLANG_DEFAULT_LINKER=lld \
      -DCLANG_DEFAULT_RTLIB=compiler-rt \
      -DCLANG_DEFAULT_UNWINDLIB=libgcc \
      -DSANITIZER_AMDGPU=OFF \
      -DPACKAGE_VENDOR="AMD" \
      -DCLANG_LINK_FLANG_LEGACY=ON \
      -DCMAKE_SKIP_BUILD_RPATH=TRUE \
      -DCMAKE_SKIP_INSTALL_RPATH=TRUE \
      -DFLANG_INCLUDE_DOCS=OFF \
      ../llvm && ninja install && cd ../../ && rm -rf llvm-project/build
      ```
      The following options can also be considered when building LLVM:
      - `-DBUILD_SHARED_LIBS=ON` will build LLVM with shared libraries instead of static. This option is very useful for
        development builds of Luthier, especially when building the LLVM project with debug information.
      - `-DCMAKE_BUILD_TYPE` can be set to `Debug` or `RelWithDebInfo` to build LLVM with debug information. Building
        with `Debug` also enables the LLVM's debugging macros and logging utilities.
      - `-DLLVM_ENABLE_ASSERTIONS` manually enables or disables assertion in LLVM. Enabling it in development builds 
        is recommended.
      Refer to [LLVM's CMake documentation](https://llvm.org/docs/CMake.html) for more information on LLVM build flags. 
   3. Configure, build, and install the AMD device libraries under the `amd/` folder of ROCm's LLVM:
      ```bash
      cd llvm-project/amd/device-libs && mkdir build && cd build &&  \
      cmake -G Ninja -DCMAKE_BUILD_TYPE=Release  \
      -DCMAKE_INSTALL_PREFIX=/opt/luthier/  \
      -DCMAKE_PREFIX_PATH="/opt/luthier/" ../ && ninja install &&
      cd ../../../ && 
      rm -rf llvm-project/amd/device-libs/build/
      ```
3. clone the Luthier project and build it:
   ```bash
   git clone https://github.com/matinraayai/luthier && cd luthier && mkdir build && \
   cmake -DCMAKE_PREFIX_PATH="/opt/luthier;/opt/rocm" -G Ninja \
   -DCMAKE_HIP_COMPILER=/opt/luthier/llvm/bin/clang++ \
   -DCMAKE_BUILD_TYPE=Release \
   -DCMAKE_HIP_FLAGS="-O3" .. && ninja
   ```
   Notable flags:
   - `-DCMAKE_BUILD_TYPE` can be set to `Debug` or `RelWithDebInfo` to emit debug information in the compiled targets.
   - `-DCMAKE_PREFIX_PATH` should specify `/opt/luthier` after `/opt/rocm` to ensure Luthier-related packages are
     given precedence over their ROCm-shipped counterparts.
   - `DCMAKE_HIP_COMPILER` must point to the `clang++` of Luthier, not the one shipped with ROCm.
   - `DLLVM_DIR` can be set to `/opt/luthier/llvm/lib/cmake/llvm/` to force CMake use the Luthier LLVM.
   - `-DLUTHIER_LLVM_SRC_DIR` can be set to point to the source code of Luthier LLVM cloned in the earlier steps. 
   - `-DCMAKE_HIP_FLAGS` should be `"-O3"`, to force CMake to emit optimized device bitcode/binary. For now unoptimized
     tool device binaries are not supported in Luthier.

> [!TIP]
> Refer to the [Luthier Dev Dockerfile](../dockerfiles/luthier-dev/Dockerfile) and the
> [ROCm Dev Dockerfile](../dockerfiles/rocm-dev/Dockerfile) for more information on satisfying the build
> requirements. You can also build the development containers from scratch, or pull it from
> `containers.rc.northeastern.edu/luthier/luthier-dev-llvm-x-y-rocm-z`, where `x` is the LLVM version used, y is the
> build type of LLVM (shared or static), and z is the ROCm version.